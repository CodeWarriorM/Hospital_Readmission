{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out models (Version Virginia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/hospital_readmissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "df = df[df['diag_1'] != 'Missing']\n",
    "df = df[df['diag_2'] != 'Missing']\n",
    "df = df[df['diag_3'] != 'Missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('readmitted', axis=1)\n",
    "y = df['readmitted'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data function\n",
    "def make_clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['n_lab_procedures_grouped'] = (df['n_lab_procedures'] // 10).astype(int)\n",
    "    df['n_medications_grouped'] = (df['n_medications'] // 5).astype(int)\n",
    "    df['n_outpatient'] = df['n_outpatient'].map({0: 0, 1: 1}).fillna(2).astype(int)\n",
    "    df['n_inpatient'] = df['n_inpatient'].map({0: 0, 1: 1}).fillna(2).astype(int)\n",
    "    df['n_emergency'] = df['n_emergency'].map({0: 0, 1: 1}).fillna(2).astype(int)\n",
    "\n",
    "    df = df.drop(columns=['n_lab_procedures',\n",
    "                          'medical_specialty',\n",
    "                          'glucose_test',\n",
    "                          'n_medications'],\n",
    "                )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for Label Encoding 'age' column\n",
    "class AgeLabelEncoder:\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder.fit(X['age'])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['age'] = self.encoder.transform(X['age'])\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;data_cleaner&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function make_clean_data at 0x304bdbc70&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;age_label_encoder&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x304d8c160&gt;),\n",
       "                                                  [&#x27;age&#x27;]),\n",
       "                                                 (&#x27;num_transf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x17f6cd360&gt;),\n",
       "                                                 (&#x27;cat_transf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;diag_1&#x27;, &#x27;diag_2&#x27;, &#x27;diag_3&#x27;,\n",
       "                                                   &#x27;A1Ctest&#x27;, &#x27;change&#x27;,\n",
       "                                                   &#x27;diabetes_med&#x27;])],\n",
       "                                   verbose_feature_names_out=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;data_cleaner&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function make_clean_data at 0x304bdbc70&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;age_label_encoder&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x304d8c160&gt;),\n",
       "                                                  [&#x27;age&#x27;]),\n",
       "                                                 (&#x27;num_transf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x17f6cd360&gt;),\n",
       "                                                 (&#x27;cat_transf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;diag_1&#x27;, &#x27;diag_2&#x27;, &#x27;diag_3&#x27;,\n",
       "                                                   &#x27;A1Ctest&#x27;, &#x27;change&#x27;,\n",
       "                                                   &#x27;diabetes_med&#x27;])],\n",
       "                                   verbose_feature_names_out=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>FunctionTransformer(func=&lt;function make_clean_data at 0x304bdbc70&gt;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;age_label_encoder&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x304d8c160&gt;),\n",
       "                                 [&#x27;age&#x27;]),\n",
       "                                (&#x27;num_transf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x17f6cd360&gt;),\n",
       "                                (&#x27;cat_transf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;diag_1&#x27;, &#x27;diag_2&#x27;, &#x27;diag_3&#x27;, &#x27;A1Ctest&#x27;,\n",
       "                                  &#x27;change&#x27;, &#x27;diabetes_med&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">age_label_encoder</label><div class=\"sk-toggleable__content \"><pre>[&#x27;age&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x304d8c160&gt;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">num_transf</label><div class=\"sk-toggleable__content \"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x17f6cd360&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">cat_transf</label><div class=\"sk-toggleable__content \"><pre>[&#x27;diag_1&#x27;, &#x27;diag_2&#x27;, &#x27;diag_3&#x27;, &#x27;A1Ctest&#x27;, &#x27;change&#x27;, &#x27;diabetes_med&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data_cleaner',\n",
       "                 FunctionTransformer(func=<function make_clean_data at 0x304bdbc70>)),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('age_label_encoder',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x304d8c160>),\n",
       "                                                  ['age']),\n",
       "                                                 ('num_transf',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x17f6cd360>),\n",
       "                                                 ('cat_transf',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['diag_1', 'diag_2', 'diag_3',\n",
       "                                                   'A1Ctest', 'change',\n",
       "                                                   'diabetes_med'])],\n",
       "                                   verbose_feature_names_out=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaner = FunctionTransformer(make_clean_data)\n",
    "age_label_encoder = FunctionTransformer(lambda X: AgeLabelEncoder().fit_transform(X))\n",
    "\n",
    "# Numeric preprocessing pipeline\n",
    "num_preproc = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "])\n",
    "\n",
    "# Categorical preprocessing pipeline (excluding 'age')\n",
    "categorical_columns = [col for col in data_cleaner.transform(X_train).select_dtypes(include=['object']).columns if col != 'age']\n",
    "cat_preproc = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, drop=\"if_binary\")),\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    ('age_label_encoder', age_label_encoder, ['age']),\n",
    "    ('num_transf', num_preproc, make_column_selector(dtype_include='number')),\n",
    "    ('cat_transf', cat_preproc, categorical_columns),\n",
    "], verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "pipe_preproc = Pipeline([\n",
    "    ('data_cleaner', data_cleaner),\n",
    "    ('preprocessor', preproc),\n",
    "])\n",
    "\n",
    "pipe_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_preprocessed = pipe_preproc.fit_transform(X_train)\n",
    "X_val_preprocessed = pipe_preproc.transform(X_val)\n",
    "X_test_preprocessed = pipe_preproc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Precision*** = High precision indicates that when the model predicts a readmission, it is usually correct. <br>\n",
    "***Recall*** =  High recall indicates that the model correctly identifies a high percentage of actual readmissions. <br>\n",
    "***F1-Score*** = A higher F1-score indicates a better balance between precision and recall. <br>\n",
    "***AUC-ROC*** = A higher AUC-ROC value indicates better overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Base model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.62      0.42      0.51      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.59      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6009\n"
     ]
    }
   ],
   "source": [
    "# Baseline Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_val_pred = log_reg.predict(X_val_preprocessed)\n",
    "print(\"Logistic Regression Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "logreg_score = accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6051\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_svc = svc.predict(X_val_preprocessed)\n",
    "print(\"Support Vector Classifier Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_svc))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_svc):.4f}\")\n",
    "svc_score = accuracy_score(y_val, y_val_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63      2580\n",
      "           1       0.59      0.49      0.54      2376\n",
      "\n",
      "    accuracy                           0.59      4956\n",
      "   macro avg       0.59      0.59      0.59      4956\n",
      "weighted avg       0.59      0.59      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.5914\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_rf = rf.predict(X_val_preprocessed)\n",
    "print(\"Random Forest Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf):.4f}\")\n",
    "rf_score = accuracy_score(y_val, y_val_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66      2580\n",
      "           1       0.62      0.46      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6043\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_gb = gb.predict(X_val_preprocessed)\n",
    "print(\"Gradient Boosting Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_gb))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_gb):.4f}\")\n",
    "gb_score = accuracy_score(y_val, y_val_pred_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63      2580\n",
      "           1       0.58      0.50      0.54      2376\n",
      "\n",
      "    accuracy                           0.59      4956\n",
      "   macro avg       0.59      0.59      0.58      4956\n",
      "weighted avg       0.59      0.59      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.5896\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_xgb = xgb.predict(X_val_preprocessed)\n",
    "print(\"XGBoost Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "xgb_score = accuracy_score(y_val, y_val_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      2580\n",
      "           1       0.53      0.52      0.52      2376\n",
      "\n",
      "    accuracy                           0.55      4956\n",
      "   macro avg       0.55      0.55      0.55      4956\n",
      "weighted avg       0.55      0.55      0.55      4956\n",
      "\n",
      "Validation Accuracy: 0.5468\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_dt = dt.predict(X_val_preprocessed)\n",
    "print(\"Decision Tree Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_dt))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_dt):.4f}\")\n",
    "dt_score = accuracy_score(y_val, y_val_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginiawenger/.pyenv/versions/3.10.6/envs/hospital_readmission/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.67      2580\n",
      "           1       0.62      0.44      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6045\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada.fit(X_train_preprocessed, y_train)\n",
    "y_val_pred_ada = ada.predict(X_val_preprocessed)\n",
    "print(\"AdaBoost Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_ada))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_ada):.4f}\")\n",
    "ada_score = accuracy_score(y_val, y_val_pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set evaluation with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.605125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.604520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.604318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.600888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.591404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.589588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.546812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy Score\n",
       "0                  SVC        0.605125\n",
       "1             AdaBoost        0.604520\n",
       "2    Gradient Boosting        0.604318\n",
       "3  Logistic Regression        0.600888\n",
       "4        Random Forest        0.591404\n",
       "5              XGBoost        0.589588\n",
       "6        Decision Tree        0.546812"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "accuracy = {\n",
    "    'Model': ['Logistic Regression', 'SVC', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'Decision Tree', 'AdaBoost'],\n",
    "    'Accuracy Score': [logreg_score, svc_score, rf_score, gb_score, xgb_score, dt_score, ada_score]\n",
    "}\n",
    "\n",
    "df_accuracy = pd.DataFrame(accuracy).sort_values(by='Accuracy Score', ascending=False).reset_index(drop=True)\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Performed best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67      2559\n",
      "           1       0.64      0.45      0.53      2397\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.62      0.60      0.60      4956\n",
      "weighted avg       0.62      0.61      0.60      4956\n",
      "\n",
      "Test Accuracy: 0.6098\n"
     ]
    }
   ],
   "source": [
    "best_model = svc\n",
    "y_test_pred = best_model.predict(X_test_preprocessed)\n",
    "print(\"Best Model Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "time_in_hospital: 0.12884751203103628\n",
      "n_lab_procedures_grouped: 0.12624797520263553\n",
      "n_medications_grouped: 0.09866111485880502\n",
      "age: 0.09374283664293735\n",
      "n_procedures: 0.07557675430125879\n",
      "n_inpatient: 0.05534677859380795\n",
      "n_outpatient: 0.02733585015011078\n",
      "change_yes: 0.02721658217557083\n",
      "diag_3_Other: 0.0245310029121059\n",
      "diag_2_Other: 0.023594809632032452\n",
      "diag_3_Circulatory: 0.023493829589252047\n",
      "n_emergency: 0.02250831369068293\n",
      "diag_2_Circulatory: 0.02199985963899063\n",
      "diag_1_Circulatory: 0.02108102652554416\n",
      "diag_1_Other: 0.02001184218094527\n",
      "diabetes_med_yes: 0.018372978544288866\n",
      "diag_3_Diabetes: 0.017872110038462525\n",
      "diag_2_Respiratory: 0.015459968628364868\n",
      "diag_1_Respiratory: 0.015249602884206272\n",
      "A1Ctest_no: 0.014782658394159076\n",
      "diag_2_Diabetes: 0.014668757405636914\n",
      "diag_3_Respiratory: 0.013595855785554748\n",
      "diag_1_Digestive: 0.01329924514041762\n",
      "A1Ctest_high: 0.011868752153326681\n",
      "diag_1_Injury: 0.0108592496386813\n",
      "diag_1_Diabetes: 0.010575327481697056\n",
      "diag_3_Digestive: 0.008363855338772068\n",
      "diag_2_Digestive: 0.008231015174164458\n",
      "A1Ctest_normal: 0.007824579139107647\n",
      "diag_1_Musculoskeletal: 0.007419014365291365\n",
      "diag_2_Injury: 0.006061886783427366\n",
      "diag_3_Musculoskeletal: 0.005702514664505062\n",
      "diag_3_Injury: 0.005188562423891908\n",
      "diag_2_Musculoskeletal: 0.004407977890328105\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection using RandomForestClassifier feature importance\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Print feature importance\n",
    "print(\"Feature Importances:\")\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{X_train_preprocessed.columns[idx]}: {feature_importances[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance with top 1 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67      2580\n",
      "           1       0.49      0.07      0.13      2376\n",
      "\n",
      "    accuracy                           0.52      4956\n",
      "   macro avg       0.51      0.50      0.40      4956\n",
      "weighted avg       0.51      0.52      0.41      4956\n",
      "\n",
      "Validation Accuracy: 0.5194\n",
      "Validation Performance with top 2 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.97      0.68      2580\n",
      "           1       0.49      0.03      0.06      2376\n",
      "\n",
      "    accuracy                           0.52      4956\n",
      "   macro avg       0.51      0.50      0.37      4956\n",
      "weighted avg       0.51      0.52      0.38      4956\n",
      "\n",
      "Validation Accuracy: 0.5202\n",
      "Validation Performance with top 3 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63      2580\n",
      "           1       0.54      0.34      0.42      2376\n",
      "\n",
      "    accuracy                           0.55      4956\n",
      "   macro avg       0.55      0.54      0.52      4956\n",
      "weighted avg       0.55      0.55      0.53      4956\n",
      "\n",
      "Validation Accuracy: 0.5464\n",
      "Validation Performance with top 4 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68      2580\n",
      "           1       0.00      0.00      0.00      2376\n",
      "\n",
      "    accuracy                           0.52      4956\n",
      "   macro avg       0.26      0.50      0.34      4956\n",
      "weighted avg       0.27      0.52      0.36      4956\n",
      "\n",
      "Validation Accuracy: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginiawenger/.pyenv/versions/3.10.6/envs/hospital_readmission/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/virginiawenger/.pyenv/versions/3.10.6/envs/hospital_readmission/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/virginiawenger/.pyenv/versions/3.10.6/envs/hospital_readmission/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance with top 5 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.68      2580\n",
      "           1       0.54      0.07      0.12      2376\n",
      "\n",
      "    accuracy                           0.53      4956\n",
      "   macro avg       0.53      0.51      0.40      4956\n",
      "weighted avg       0.53      0.53      0.41      4956\n",
      "\n",
      "Validation Accuracy: 0.5252\n",
      "Validation Performance with top 6 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66      2580\n",
      "           1       0.62      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.59      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6013\n",
      "Validation Performance with top 7 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65      2580\n",
      "           1       0.61      0.48      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6021\n",
      "Validation Performance with top 8 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6039\n",
      "Validation Performance with top 9 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6037\n",
      "Validation Performance with top 10 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6027\n",
      "Validation Performance with top 11 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6029\n",
      "Validation Performance with top 12 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6035\n",
      "Validation Performance with top 13 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6021\n",
      "Validation Performance with top 14 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6013\n",
      "Validation Performance with top 15 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.65      2580\n",
      "           1       0.61      0.47      0.53      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6013\n",
      "Validation Performance with top 16 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.66      2580\n",
      "           1       0.61      0.46      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.59      0.59      4956\n",
      "weighted avg       0.60      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6003\n",
      "Validation Performance with top 17 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      2580\n",
      "           1       0.61      0.45      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6009\n",
      "Validation Performance with top 18 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      2580\n",
      "           1       0.61      0.46      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.60      0.60      0.59      4956\n",
      "weighted avg       0.60      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6017\n",
      "Validation Performance with top 19 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      2580\n",
      "           1       0.62      0.45      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6023\n",
      "Validation Performance with top 20 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      2580\n",
      "           1       0.62      0.45      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6023\n",
      "Validation Performance with top 21 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66      2580\n",
      "           1       0.62      0.45      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6031\n",
      "Validation Performance with top 22 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66      2580\n",
      "           1       0.62      0.45      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6035\n",
      "Validation Performance with top 23 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      2580\n",
      "           1       0.62      0.44      0.52      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6049\n",
      "Validation Performance with top 24 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.62      0.44      0.52      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6051\n",
      "Validation Performance with top 25 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67      2580\n",
      "           1       0.63      0.44      0.52      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.60      4956\n",
      "\n",
      "Validation Accuracy: 0.6069\n",
      "Validation Performance with top 26 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.63      0.44      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6057\n",
      "Validation Performance with top 27 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6055\n",
      "Validation Performance with top 28 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6057\n",
      "Validation Performance with top 29 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6057\n",
      "Validation Performance with top 30 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6059\n",
      "Validation Performance with top 31 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6055\n",
      "Validation Performance with top 32 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6057\n",
      "Validation Performance with top 33 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.60      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.60      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6049\n",
      "Validation Performance with top 34 features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67      2580\n",
      "           1       0.63      0.43      0.51      2376\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.61      0.60      0.59      4956\n",
      "weighted avg       0.61      0.61      0.59      4956\n",
      "\n",
      "Validation Accuracy: 0.6051\n",
      "Best k: 25 with Validation Accuracy: 0.6069\n"
     ]
    }
   ],
   "source": [
    "# Select top k features based on importance (loop)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "k_values = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# Loop over different values of k\n",
    "for k in range(1, len(sorted_idx) + 1):\n",
    "    selected_features = X_train_preprocessed.columns[sorted_idx][:k]\n",
    "\n",
    "    # Subset X_train_preprocessed and X_val_preprocessed with selected features\n",
    "    X_train_selected = X_train_preprocessed[selected_features]\n",
    "    X_val_selected = X_val_preprocessed[selected_features]\n",
    "\n",
    "    # Retrain the SVC model with selected features\n",
    "    svc = SVC(random_state=42)\n",
    "    svc.fit(X_train_selected, y_train)\n",
    "    y_val_pred_svc = svc.predict(X_val_selected)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred_svc)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "    k_values.append(k)\n",
    "\n",
    "    #print(f\"Validation Performance with top {k} features\")\n",
    "    #print(classification_report(y_val, y_val_pred_svc))\n",
    "    #print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Determine the best k based on the highest validation accuracy\n",
    "best_k = k_values[np.argmax(validation_accuracies)]\n",
    "best_accuracy = max(validation_accuracies)\n",
    "\n",
    "print(f\"Best k: {best_k} with Validation Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Test Performance with Best Selected Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      2559\n",
      "           1       0.63      0.46      0.53      2397\n",
      "\n",
      "    accuracy                           0.61      4956\n",
      "   macro avg       0.62      0.60      0.60      4956\n",
      "weighted avg       0.61      0.61      0.60      4956\n",
      "\n",
      "Test Accuracy: 0.6098\n"
     ]
    }
   ],
   "source": [
    "# Retrain the SVC model with the best k features on the test set\n",
    "best_selected_features = X_train_preprocessed.columns[sorted_idx][:best_k]\n",
    "X_train_best_selected = X_train_preprocessed[best_selected_features]\n",
    "X_val_best_selected = X_val_preprocessed[best_selected_features]\n",
    "X_test_best_selected = X_test_preprocessed[best_selected_features]\n",
    "\n",
    "svc_best = SVC(random_state=42)\n",
    "svc_best.fit(X_train_best_selected, y_train)\n",
    "y_test_pred_svc_best = svc_best.predict(X_test_best_selected)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "print(\"Support Vector Classifier Test Performance with Best Selected Features\")\n",
    "print(classification_report(y_test, y_test_pred_svc_best))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_svc_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection did not improve my score by very much. I keep 25 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 20, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5,  n_jobs=-1, scoring='accuracy', verbose=0)\n",
    "grid_search.fit(X_train_best_selected, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set using the best model\n",
    "y_val_pred_best_svc = best_svc.predict(X_val_best_selected)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "print(\"Best SVC Model Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_best_svc))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_best_svc):.4f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "X_test_best_selected = X_test_preprocessed[best_selected_features]\n",
    "y_test_pred_best_svc = best_svc.predict(X_test_best_selected)\n",
    "\n",
    "print(\"Best SVC Model Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_best_svc))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_best_svc):.4f}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "random_search_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_dist_rf, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_rf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best parameters from the randomized search\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "print(f\"Best parameters for RandomForest: {best_params_rf}\")\n",
    "\n",
    "# Retrain the model with the best parameters\n",
    "rf_best = RandomForestClassifier(random_state=42, **best_params_rf)\n",
    "rf_best.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "y_val_pred_rf_best = rf_best.predict(X_val_selected)\n",
    "y_test_pred_rf_best = rf_best.predict(X_test_selected)\n",
    "\n",
    "print(\"RandomForest Validation Performance with Best Parameters\")\n",
    "print(classification_report(y_val, y_val_pred_rf_best))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf_best):.4f}\")\n",
    "\n",
    "print(\"RandomForest Test Performance with Best Parameters\")\n",
    "print(classification_report(y_test, y_test_pred_rf_best))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_rf_best):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_gb = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'learning_rate': uniform(0.01, 0.2),  # Randomly sample learning rates between 0.01 and 0.21\n",
    "    'max_depth': randint(3, 8),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "random_search_gb = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=42), param_distributions=param_dist_gb, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_gb.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best parameters from the randomized search\n",
    "best_params_gb = random_search_gb.best_params_\n",
    "print(f\"Best parameters for GradientBoosting: {best_params_gb}\")\n",
    "\n",
    "# Retrain the model with the best parameters\n",
    "gb_best = GradientBoostingClassifier(random_state=42, **best_params_gb)\n",
    "gb_best.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "y_val_pred_gb_best = gb_best.predict(X_val_selected)\n",
    "y_test_pred_gb_best = gb_best.predict(X_test_selected)\n",
    "\n",
    "print(\"GradientBoosting Validation Performance with Best Parameters\")\n",
    "print(classification_report(y_val, y_val_pred_gb_best))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_gb_best):.4f}\")\n",
    "\n",
    "print(\"GradientBoosting Test Performance with Best Parameters\")\n",
    "print(classification_report(y_test, y_test_pred_gb_best))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_gb_best):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_lr = {\n",
    "    'C': uniform(0.01, 100),  # Randomly sample C values from 0.01 to 100.01\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "random_search_lr = RandomizedSearchCV(estimator=LogisticRegression(random_state=42), param_distributions=param_dist_lr, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_lr.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best parameters from the randomized search\n",
    "best_params_lr = random_search_lr.best_params_\n",
    "print(f\"Best parameters for LogisticRegression: {best_params_lr}\")\n",
    "\n",
    "# Retrain the model with the best parameters\n",
    "lr_best = LogisticRegression(random_state=42, **best_params_lr)\n",
    "lr_best.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "y_val_pred_lr_best = lr_best.predict(X_val_selected)\n",
    "y_test_pred_lr_best = lr_best.predict(X_test_selected)\n",
    "\n",
    "print(\"LogisticRegression Validation Performance with Best Parameters\")\n",
    "print(classification_report(y_val, y_val_pred_lr_best))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_lr_best):.4f}\")\n",
    "\n",
    "print(\"LogisticRegression Test Performance with Best Parameters\")\n",
    "print(classification_report(y_test, y_test_pred_lr_best))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_lr_best):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble using VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', best_svc),\n",
    "        ('rf', rf_best),\n",
    "        ('gb', gb_best),\n",
    "        ('lr', lr_best)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit the ensemble model\n",
    "voting_clf.fit(X_train_best_selected, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_ensemble = voting_clf.predict(X_val_best_selected)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "print(\"Ensemble Model Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_ensemble))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_ensemble):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance on the test set\n",
    "y_test_pred_ensemble = voting_clf.predict(X_test_best_selected)\n",
    "\n",
    "print(\"Ensemble Model Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_ensemble))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_ensemble):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for validation set\n",
    "cm_val = confusion_matrix(y_val, y_val_pred_ensemble)\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm_test = confusion_matrix(y_test, y_test_pred_ensemble)\n",
    "\n",
    "# Plot confusion matrix for validation set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for validation set\n",
    "print(\"Classification Report - Validation Set\")\n",
    "print(classification_report(y_val, y_val_pred_ensemble))\n",
    "\n",
    "# Classification report for test set\n",
    "print(\"Classification Report - Test Set\")\n",
    "print(classification_report(y_test, y_test_pred_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Analysis on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify false positives and false negatives in validation set\n",
    "val_errors = X_val[y_val != y_val_pred_ensemble]\n",
    "val_errors['actual'] = y_val[y_val != y_val_pred_ensemble]\n",
    "val_errors['predicted'] = y_val_pred_ensemble[y_val != y_val_pred_ensemble]\n",
    "\n",
    "print(\"Validation Set Errors\")\n",
    "print(val_errors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Error Analysis on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify false positives and false negatives in test set\n",
    "test_errors = X_test[y_test != y_test_pred_ensemble]\n",
    "test_errors['actual'] = y_test[y_test != y_test_pred_ensemble]\n",
    "test_errors['predicted'] = y_test_pred_ensemble[y_test != y_test_pred_ensemble]\n",
    "\n",
    "print(\"Test Set Errors\")\n",
    "print(test_errors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distribution for validation set errors\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(selected_features):\n",
    "    plt.subplot(4, 2, i + 1)\n",
    "    sns.histplot(val_errors[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature} in Validation Errors')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature distribution for test set errors\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(selected_features):\n",
    "    plt.subplot(4, 2, i + 1)\n",
    "    sns.histplot(test_errors[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature} in Test Errors')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Plot learning curve for the best model\n",
    "plot_learning_curve(best_model, \"Learning Curve for Best Model\", X_train_selected, y_train, cv=5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
